#!/bin/bash

# about data:
# required:  under path param_dataset_path:
#    - wadi/
#       anomaly_pc4.npy
#       normal_pc4.npy
#    - swat/
#       anomaly_pc.npy
#       normal_pc.npy
#


# files generated by bnaf:
# checkpoint of model:
#     "checkpoint.txt" indicate the path to checkpoint
# use trained model to convert xxxxx_pcx.npy:
#     generate: xxxxx_1.npy in the same directory as xxxxx_pcx.npy
#

#
# parameters
#
param_dataset=wadi
param_convert_dataset_type=anomaly
param_train_dataset_type=normal
param_dataset_path=/home/caizhuo/research/anomaly/data/
param_data_filename=_np2.npy
param_flows=2
param_layers=2
param_hidden_dim=20
param_epochs=1
param_train_device=cuda:0
param_convert_device=cuda:0

# training
#python -W ignore anomaly_estimation.py --dataset $param_dataset \
#	--dataset_type $param_train_dataset_type \
#	--dataset_path $param_dataset_path \
#	--flows $param_flows \
#	--layers $param_layers \
#	--device $param_train_device \
#	--hidden_dim $param_hidden_dim \
#	--save \
#	--epochs $param_epochs

param_checkpoint_path=$(cat checkpoint_path.txt)

# convert model
python -W ignore anomaly_estimation.py --dataset $param_dataset \
	--device $param_convert_device \
	--dataset_type $param_convert_dataset_type \
	--dataset_path $param_dataset_path \
	--dataset_filename $param_data_filename \
	--is_training 0 \
	--flows $param_flows \
	--layers $param_layers \
	--hidden_dim $param_hidden_dim \
	--load "$param_checkpoint_path"


